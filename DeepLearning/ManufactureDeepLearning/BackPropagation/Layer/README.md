### ファイルの説明
---
mul_layer.py : 誤差逆伝搬法の乗算レイヤを, 自分で実装した。  
* 課題点について  
1. 逆伝搬する際に, １つ１つ変数を保存する必要性がある。自分のコードでは各ノードの入力である, 各arr[0], arr[1]について保存することができていない。   
 -> ここでの数値の保存についてだが, インスタンスを複数作成することで, 逆伝搬時の値を保持していた。  
2. 課題点かわからないが, 自分のコードでは出力値を, 自分のクラス内から参照しようとした。  

---
layer_naive.py : 教科書を参照に, 乗算レイヤを作成した。  

---
add_layer.py : 誤差逆伝搬の加算レイヤを, 自分で実装した。
* 課題点について
1. __init__の部分をpassに  
2. これを考えるとforwardの所の計算を変わってくる  
3. ２つの値が必要であるから, dx, dyを返すようにする  

---
add_mul_layer.py : 加算レイヤと乗算レイヤが実装されている。  

---
apple_mikan_layer.py : P.140の加算レイヤ, 乗算レイヤの図を実装してみる。このプログラムは教科書の図を参考に, 自分自身で実装したものである。  
* 課題点について
1. 特になし  

---
relu_layer.py : 活性化関数ReLUの順伝搬, 逆伝搬の実装。このプログラムはP.142の図を参照に自分で実装したものである。  
* 課題点について
1. 実際は配列で受け取るので, 配列に対応すべきである 

---
sigmoid_layer.py : 活性化関数Sigmoidの順伝搬, 逆伝搬の実装。このプログラムはP.146の図を参照に自分で実装したものである。  
* 課題点について  
1. 逆伝搬時の1から引くところが1.0に直すべき  

---
affine_layer.py : ニューラルネットワークのAffine変換の部分が, 簡単に実装されている。  
* 課題点について  
1. 計算グラフからプログラムを記述することができなかった。  
2. Affine変換の逆伝搬時の値を返す個数  
3. 最終的な実装はcommon/layerに記述してある。  

---
softmax_with_loss_layer.py : ニューラルネットワークの出力関数のsoftmax関数と, 誤差関数の交差エントロピー関数を自分で実装したもの  
* 課題点について  
1. 解答では初期化関数でself.loss = Noneで初期化  
2. バッチ学習に対応していない      
 
